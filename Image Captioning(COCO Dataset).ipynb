{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pycocotools'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-42898c77a6fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpycocotools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoco\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCOCO\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# initialize COCO API for instance annotations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdataDir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pycocotools'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "# initialize COCO API for instance annotations\n",
    "dataDir = ''\n",
    "dataType = 'train2014'\n",
    "instances_annFile = os.path.join(dataDir, 'coco/annotations/annotations/instances_train2014.json'.format(dataType))\n",
    "coco = COCO(instances_annFile)\n",
    "\n",
    "# initialize COCO API for caption annotations\n",
    "captions_annFile = os.path.join(dataDir, 'coco/annotations/annotations/captions_train2014.json'.format(dataType))\n",
    "coco_caps = COCO(captions_annFile)\n",
    "\n",
    "# get image ids \n",
    "ids = list(coco.anns.keys())\n",
    "len(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dense, Flatten,Input, Convolution2D, Dropout, LSTM, TimeDistributed, Embedding, Bidirectional, Activation, RepeatVector,Concatenate\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import np_utils\n",
    "import random\n",
    "from keras.preprocessing import image, sequence\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# pick a random image and obtain the corresponding URL\n",
    "ann_id = np.random.choice(ids)\n",
    "img_id = coco.anns[ann_id]['image_id']\n",
    "img = coco.loadImgs(img_id)[0]\n",
    "url = img['coco_url']\n",
    "# print URL and visualize corresponding image\n",
    "print(url)\n",
    "I = io.imread(url)\n",
    "plt.axis('off')\n",
    "plt.imshow(I)\n",
    "plt.show()\n",
    "\n",
    "# load and display captions\n",
    "annIds = coco_caps.getAnnIds(imgIds=img['id']);\n",
    "print(annIds)\n",
    "anns = coco_caps.loadAnns(annIds)\n",
    "print(anns)\n",
    "coco_caps.showAnns(anns)\n",
    "anns[0]['caption']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = {}\n",
    "for i in ids:\n",
    "    img_id = coco.anns[i]['image_id']\n",
    "    if img_id in image_ids:\n",
    "        continue\n",
    "    else:\n",
    "        image_ids[img_id]=i\n",
    "        \n",
    "len(image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = {}\n",
    "x_train = []\n",
    "unique = {}\n",
    "c=1\n",
    "for i in image_ids:\n",
    "    img = coco.loadImgs(i)[0]\n",
    "    file_name = img['file_name']\n",
    "    annIds = coco_caps.getAnnIds(imgIds=img['id']);\n",
    "    anns = coco_caps.loadAnns(annIds)\n",
    "   # print(file_name)\n",
    "    #tokens[file_name] = []\n",
    "    for j in range(0,5):\n",
    "        if file_name in tokens:\n",
    "            tokens[file_name].append(anns[j]['caption'])\n",
    "        else:\n",
    "            x_train.append(file_name)\n",
    "            tokens[file_name] = [anns[j]['caption']]\n",
    "    \n",
    "print(len(ids))\n",
    "print(len(x_train))\n",
    "print(c)\n",
    "len(tokens['COCO_train2014_000000480023.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to process images\n",
    "def preprocessing(img_path):\n",
    "    im = image.load_img(img_path, target_size=(224,224,3))\n",
    "    im = image.img_to_array(im)\n",
    "    im = np.expand_dims(im, axis=0)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading 50 layer Residual Network Model and getting the summary of the model\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"\"\"<a href=\"http://ethereon.github.io/netscope/#/gist/db945b393d40bfa26006\">ResNet50 Architecture</a>\"\"\"))\n",
    "model = ResNet50(include_top=False,weights='imagenet',input_shape=(224,224,3),pooling='avg')\n",
    "model.summary()\n",
    "# Note: For more details on ResNet50 architecture you can click on hyperlink given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = {}\n",
    "images_path = 'coco/coco-train/train2014/'\n",
    "ctr=1\n",
    "for ix in x_train:\n",
    "    if ix == \"\":\n",
    "        continue\n",
    "    if ctr>= 82784:\n",
    "        break\n",
    "    #print(ix)\n",
    "    path = images_path + ix\n",
    "    img = preprocessing(path)\n",
    "    pred = model.predict(img).reshape(2048)\n",
    "    train_data[ix] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = open('coco/coco-train/coco-train-dataset.txt','wb')\n",
    "train_dataset.write(b\"image_id\\tcaptions\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=1\n",
    "j=1\n",
    "for img in x_train:\n",
    "    if img == '':\n",
    "        continue\n",
    "    for capt in tokens[img]:\n",
    "        if capt == \"\":\n",
    "            continue\n",
    "        if i==1:\n",
    "            print(j)\n",
    "            j=j+1\n",
    "        caption = \"<start> \"+ capt + \" <end>\"\n",
    "        train_dataset.write((img+\"\\t\"+caption+\"\\n\").encode())\n",
    "        train_dataset.flush()\n",
    "    i = i+1\n",
    "train_dataset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opening train_encoded_images.p file and dumping it's content\n",
    "with open( \"coco/train_encoded_images.p\", \"wb\" ) as pickle_f:\n",
    "    pickle.dump(train_data, pickle_f )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading image and its corresponding caption into a dataframe and then storing values from dataframe into 'ds'\n",
    "pd_dataset = pd.read_csv(\"coco/coco-train/coco-train-dataset.txt\", delimiter='\\t')\n",
    "pd_dataset = pd_dataset[pd_dataset['image_id'].notnull()]\n",
    "ds = pd_dataset.values\n",
    "#ds = ds[ds[i]!=\"\" for i in ds]\n",
    "print(ds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing all the captions from ds into a list\n",
    "sentences = []\n",
    "for ix in range(ds.shape[0]):\n",
    "    sentences.append(ds[ix, 1])\n",
    "    \n",
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 5 captions stored in sentences\n",
    "sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting each captions stored in 'sentences' and storing them in 'words' as list of list\n",
    "words = [str(i).split() for i in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of all unique words\n",
    "unique = []\n",
    "for i in words:\n",
    "    unique.extend(i)\n",
    "unique = list(set(unique))\n",
    "\n",
    "print(len(unique))\n",
    "\n",
    "vocab_size = len(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization\n",
    "word_2_indices = {val:index for index, val in enumerate(unique)}\n",
    "indices_2_word = {index:val for index, val in enumerate(unique)}\n",
    "word_2_indices['UNK'] = 0\n",
    "word_2_indices['raining'] = 43748\n",
    "indices_2_word[0] = 'UNK'\n",
    "indices_2_word[43748] = 'raining'\n",
    "print(word_2_indices['<start>'])\n",
    "print(indices_2_word[4011])\n",
    "print(word_2_indices['<end>'])\n",
    "print(indices_2_word[8051])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word_2_indices.keys())\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "\n",
    "for i in sentences:\n",
    "    i = str(i).split()\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_sequences, subsequent_words = [], []\n",
    "\n",
    "for ix in range(ds.shape[0]):\n",
    "    partial_seqs = []\n",
    "    next_words = []\n",
    "    text = str(ds[ix, 1]).split()\n",
    "    text = [word_2_indices[i] for i in text]\n",
    "   # print(text)\n",
    "    for i in range(1, len(text)):\n",
    "        partial_seqs.append(text[:i])\n",
    "        next_words.append(text[i])\n",
    "    padded_partial_seqs = sequence.pad_sequences(partial_seqs, max_len, padding='post')\n",
    "\n",
    "    next_words_1hot = np.zeros([len(next_words), vocab_size], dtype=np.bool)\n",
    "    \n",
    "    #Vectorization\n",
    "    for i,next_word in enumerate(next_words):\n",
    "        next_words_1hot[i, next_word] = 1\n",
    "        \n",
    "    padded_sequences.append(padded_partial_seqs)\n",
    "    subsequent_words.append(next_words_1hot)\n",
    "    \n",
    "padded_sequences = np.asarray(padded_sequences)\n",
    "subsequent_words = np.asarray(subsequent_words)\n",
    "\n",
    "print(padded_sequences.shape)\n",
    "print(subsequent_words.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(padded_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix in range(len(padded_sequences[0])):\n",
    "    for iy in range(max_len):\n",
    "        print(indices_2_word[padded_sequences[0][ix][iy]],)\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(len(padded_sequences[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_images = 2000\n",
    "captions = np.zeros([0, max_len])\n",
    "next_words = np.zeros([0, vocab_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
